{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Speech-to-Text with Whisper API and your Device Microphone\n",
    "\n",
    "Learn how to record audio from your device's microphone, transcribe the audio using OpenAI's Whisper API, and copy the transcription result to your clipboard (optional).\n",
    "\n",
    "### Setup\n",
    "\n",
    "`brew install portaudio`\n",
    "`pip install pyaudio wave openai tempfile simpleaudio os`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa\n",
    "import openai\n",
    "import pyaudio\n",
    "import wave\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def transcribe_audio(runPlayback=False):\n",
    "    \"\"\"\n",
    "    Records audio directly from the microphone and transcribes it to text using OpenAI's API.\n",
    "\n",
    "    Returns:\n",
    "        str: The transcription of the recorded audio.\n",
    "    \"\"\"\n",
    "    # Create a temporary file to store the recorded audio\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    temp_file_name = temp_file.name\n",
    "\n",
    "    def callback(data_input, frame_count, time_info, status):\n",
    "        wav_file.writeframes(data_input)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    # Open the wave file for writing\n",
    "    with wave.open(temp_file_name, 'wb') as wav_file:\n",
    "        wav_file.setnchannels(1)\n",
    "        wav_file.setsampwidth(2)  # 16 bits per sample divided by 8\n",
    "        wav_file.setframerate(16000)\n",
    "\n",
    "        # Initialize PyAudio and start recording audio\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=pyaudio.paInt16,\n",
    "                            channels=1,\n",
    "                            rate=16000,\n",
    "                            input=True,\n",
    "                            frames_per_buffer=1024,\n",
    "                            stream_callback=callback)\n",
    "\n",
    "        input(\"Press Enter to stop recording...\")\n",
    "\n",
    "        # Stop and close the audio stream\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "    # Play the recorded audio - debug\n",
    "    if runPlayback:\n",
    "        playback = sa.WaveObject.from_wave_file(temp_file.name)\n",
    "        play_obj = playback.play()\n",
    "        play_obj.wait_done()  # Wait until playback is finished\n",
    "\n",
    "    # Transcribe the audio to text using OpenAI's API\n",
    "    with open(temp_file_name, 'rb') as audio_file:\n",
    "        response = openai.Audio.transcribe(\n",
    "            file=audio_file,\n",
    "            model=\"whisper-1\",\n",
    "            prompt=\"Carl talks to Hadavand\"\n",
    "        )\n",
    "        transcription = response['text'].strip()\n",
    "\n",
    "    # Delete the temporary audio file\n",
    "    os.remove(temp_file_name)\n",
    "\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunPlayback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 51\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[0;34m(runPlayback)\u001b[0m\n\u001b[1;32m     48\u001b[0m     audio\u001b[38;5;241m.\u001b[39mterminate()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Play the recorded audio - debug\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Transcribe the audio to text using OpenAI's API\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(temp_file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n",
      "Cell \u001b[0;32mIn[43], line 9\u001b[0m, in \u001b[0;36mdebug\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug\u001b[39m():\n\u001b[0;32m----> 9\u001b[0m     playback \u001b[38;5;241m=\u001b[39m sa\u001b[38;5;241m.\u001b[39mWaveObject\u001b[38;5;241m.\u001b[39mfrom_wave_file(\u001b[43mtemp_file\u001b[49m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m     10\u001b[0m     play_obj \u001b[38;5;241m=\u001b[39m playback\u001b[38;5;241m.\u001b[39mplay()\n\u001b[1;32m     11\u001b[0m     play_obj\u001b[38;5;241m.\u001b[39mwait_done()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'temp_file' is not defined"
     ]
    }
   ],
   "source": [
    "transcribe_audio(runPlayback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
