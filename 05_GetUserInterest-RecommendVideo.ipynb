{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BreakItDown Tasks\n",
    "\n",
    "### 1. Mark video as watched\n",
    "- If ID exist\n",
    "- query result skip over id and check again if ID exists\n",
    "- repeat until not \n",
    "\n",
    "### 2. Revised percentage calculation (relative instead of 100%)\n",
    "Will cause a tag to be dominant tho (weight 1000 while others still 10). Mitigated with intentional interruptions (#4). \n",
    "\n",
    "### 3. User class schema\n",
    "- self\n",
    "- interest_weights (dict)\n",
    "- watched_videos (dict)\n",
    "\n",
    "### 4. Intentional Interruptions\n",
    "Handle dominations\n",
    "- 50% -> Suggest relevant interests \n",
    "- 75% -> \"Have you been enjoying {tag name} so far? \"yes\". \"recommend more\". \n",
    "\n",
    "### 5. Modify whisper prompt to return most relevant tag first then extract that for on_user_swipe()\n",
    "in [github](https://github.com/edgurinc/edgur/blob/main/backend/accounts/videoprocessors.py)\n",
    "- To help us later in handling which tag to add weights to given videos have multiple tags. \n",
    "\n",
    "### 6. Decay other interests whenever watching a video\n",
    "except current video tag \n",
    "\n",
    "### 7. Handle irrelevant tags\n",
    "Acknowledge that it will be filled soon, such as \"food\" category\n",
    "\n",
    "### 8. \"Cache\" next 4 videos\n",
    "Run uniformDist+reco only on 4th video \n",
    "\n",
    "### 9. Min selection Max selection for categories\n",
    "Like tiktok's\n",
    "\n",
    "### 10. Show this to me again (#SpacedRepetition)\n",
    "Remove from watched dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# User Interest Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "\n",
    "new_video_weight = 3\n",
    "starting_weight = 3\n",
    "\n",
    "user_min_interest = 4\n",
    "user_max_interest = 8\n",
    "\n",
    "queued_videos_count = 3\n",
    "# Number of vids to queue before running query again (to save costs)\n",
    "# AKA n_results = 3.\n",
    "\n",
    "# User Actions\n",
    "Like = 0.1\n",
    "Share = 0.2\n",
    "Watch = 0.1  # more than 50% of total duration\n",
    "Loop = 0.1\n",
    "\n",
    "natural_decay_rate = 0.1\n",
    "\n",
    "# Dictionaries - remove\n",
    "watched_videos = {}\n",
    "\n",
    "\n",
    "# Simulation Only (replace user input)\n",
    "chosen_tag = \"Microwave\"\n",
    "user1_interests = [\"DevOps\", \"Tests (SAT)\", \"Machine Learning\", \"Cats\", \"Cooking\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_interest_dict(user_interest_list):\n",
    "    user_dict_interest = {interest: starting_weight for interest in user_interest_list}\n",
    "    user_dict_interest[\"Random\"] = starting_weight\n",
    "    return user_dict_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS for update_weight\n",
    "\n",
    "# User actions\n",
    "\n",
    "def observe_action_taken(video_tag, liked=False, shared=False, watched=False, loop_count=0):\n",
    "    \"\"\"\n",
    "    This function calculates the total points based on the user's actions.\n",
    "\n",
    "    Parameters:\n",
    "    video_tag (str): The tag of the video.\n",
    "    liked (bool): Whether the user liked the video.\n",
    "    shared (bool): Whether the user shared the video.\n",
    "    watched (bool): Whether the user watched the video.\n",
    "    loop_count (int): The number of times the user looped the video.\n",
    "\n",
    "    Returns:\n",
    "    float: The total points calculated based on the user's actions.\n",
    "    \"\"\"\n",
    "    # Actions and their corresponding points to add\n",
    "    Actions = {\n",
    "        \"Like\": Like,\n",
    "        \"Share\": Share,\n",
    "        \"Watch\": Watch,  # more than 50% of total duration\n",
    "        # todo: experiment with increasing watch value\n",
    "        \"Loop\": Loop,\n",
    "    }\n",
    "\n",
    "    total_action_points = 0\n",
    "\n",
    "    if liked:\n",
    "        total_action_points += Actions[\"Like\"]\n",
    "    if shared:\n",
    "        total_action_points += Actions[\"Share\"]\n",
    "    if watched:\n",
    "        total_action_points += Actions[\"Watch\"]\n",
    "    total_action_points += loop_count * Actions[\"Loop\"]\n",
    "\n",
    "    print(f\"\\nUpdating weights for video tag: {video_tag}\")\n",
    "    print(f\"Total points to add: {total_action_points}\")\n",
    "\n",
    "    return total_action_points\n",
    "\n",
    "def handle_update_weight(user_dict_interest, video_tag, total_action_points):\n",
    "\n",
    "    # Increase the weight of the interest based on the action points\n",
    "    user_dict_interest[video_tag] += total_action_points\n",
    "\n",
    "    for interest in user_dict_interest:\n",
    "        if interest != \"Random\" and interest != video_tag:\n",
    "            user_dict_interest[interest] -= natural_decay_rate\n",
    "\n",
    "    return user_dict_interest\n",
    "\n",
    "def handle_add_new_tag(user_dict_interest, video_tag):\n",
    "    # Add new interest if it doesn't exist and give initial points\n",
    "    user_dict_interest[video_tag] = starting_weight\n",
    "\n",
    "    # Decrease the weight of all other interests by the natural decay rate\n",
    "    for interest in user_dict_interest:\n",
    "        if interest != \"Random\" and interest != video_tag:\n",
    "            user_dict_interest[interest] -= natural_decay_rate\n",
    "\n",
    "    return user_dict_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watch_video_and_update_weight(\n",
    "    user_dict_interest,\n",
    "    video_tag,\n",
    "    liked=False,\n",
    "    shared=False,\n",
    "    watched=False,\n",
    "    loop_count=0,\n",
    "):\n",
    "\n",
    "    total_points = observe_action_taken(video_tag, liked, shared, watched, loop_count)\n",
    "\n",
    "    if video_tag in user_dict_interest:\n",
    "        handle_update_weight(user_dict_interest, video_tag, total_points)\n",
    "    else:\n",
    "        handle_add_new_tag(user_dict_interest, video_tag)\n",
    "\n",
    "    # Sort the interests (\"key=item[1]\") by weight in descending order and keep only the top 10\n",
    "    user_dict_interest = dict(\n",
    "        sorted(user_dict_interest.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    )\n",
    "\n",
    "\n",
    "    return user_dict_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_tag_for_recommendation(user_dict_interest):\n",
    "\n",
    "    total_score = sum(value for value in user_dict_interest.values())\n",
    "    random_value = round(random.uniform(0, total_score), 0)\n",
    "\n",
    "    print(\"_\" * 50)\n",
    "    print(f\"\\nRandom value: {random_value}\\n\")\n",
    "\n",
    "    cumulative_probability = 0.0\n",
    "    partitions = []\n",
    "\n",
    "    for interest, probability in user_dict_interest.items():\n",
    "        # Save the starting point of the current tag's range (in probability)\n",
    "        previous_cumulative_probability = cumulative_probability\n",
    "\n",
    "        # Add the tag's probability to the cumulative total to get the end point of the tag's range\n",
    "        cumulative_probability += probability\n",
    "\n",
    "        partitions.append(\n",
    "            (interest, previous_cumulative_probability, cumulative_probability)\n",
    "        )\n",
    "\n",
    "        pprint(\n",
    "            f\"Checking interest: {interest}, cumulative range: {previous_cumulative_probability} - {cumulative_probability}\"\n",
    "        )\n",
    "\n",
    "        # If the random value is less than or equal to the cumulative probability up to the current interest,\n",
    "        # select the current interest and stop looking at the rest of the interests.\n",
    "        if random_value <= cumulative_probability:\n",
    "            print(f\"\\nSelected interest: {interest}\\n\")\n",
    "            break\n",
    "\n",
    "    if interest == \"Random\":\n",
    "        interest = random.choice(list(user_dict_interest.keys()))\n",
    "        print(f\"Random tag selected: {interest}\")\n",
    "        print(\"MODIFY THIS LATER TO POINT TO CSV COLUMN\")\n",
    "        return interest\n",
    "\n",
    "    return interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial user-chosen interests\n",
      "\n",
      "(\"{'DevOps': 3, 'Tests (SAT)': 3, 'Machine Learning': 3, 'Cats': 3, 'Cooking': \"\n",
      " \"3, 'Random': 3}\\n\")\n",
      "\n",
      "Updating weights for video tag: Cooking\n",
      "Total points to add: 0.2\n",
      "\n",
      "Updating weights for video tag: Shiba\n",
      "Total points to add: 0.2\n",
      "__________________________________________________\n",
      "\n",
      "Random value: 16.0\n",
      "\n",
      "'Checking interest: DevOps, cumulative range: 0.0 - 2.9'\n",
      "'Checking interest: Tests (SAT), cumulative range: 2.9 - 5.8'\n",
      "'Checking interest: Machine Learning, cumulative range: 5.8 - 8.7'\n",
      "'Checking interest: Cats, cumulative range: 8.7 - 11.6'\n",
      "'Checking interest: Cooking, cumulative range: 11.6 - 14.5'\n",
      "'Checking interest: Random, cumulative range: 14.5 - 17.5'\n",
      "\n",
      "Selected interest: Random\n",
      "\n",
      "Random tag selected: Random\n",
      "MODIFY THIS LATER TO POINT TO CSV COLUMN\n",
      "{'Cats': 2.9,\n",
      " 'Cooking': 2.9,\n",
      " 'DevOps': 2.9,\n",
      " 'Machine Learning': 2.9,\n",
      " 'Random': 3,\n",
      " 'Shiba': 3,\n",
      " 'Tests (SAT)': 2.9}\n"
     ]
    }
   ],
   "source": [
    "# Sample usage\n",
    "user_interests = create_user_interest_dict(user1_interests)\n",
    "print(\"Initial user-chosen interests\\n\")\n",
    "pprint(f\"{user_interests}\\n\")\n",
    "\n",
    "total_action_points = observe_action_taken(\"Cooking\", True, False, True, 0)\n",
    "\n",
    "watch_video_and_update_weight(user_interests, \"Shiba\", True, False, True, 0)\n",
    "\n",
    "get_random_tag_for_recommendation(user_interests)\n",
    "\n",
    "pprint(user_interests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ranking Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"db\")\n",
    "\n",
    "# Use OpenAI as the embedding model (word to vector)\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=\"sk-\",\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )\n",
    "\n",
    "# Set the URL and initialize ChromaDB client\n",
    "url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSAE2tBAnAdXsxk9a9YClFN7MSEVhzEmJD01ewwtooMLxL-Ilod26EbdD8sZeZk0ybiqD-jqT-9RZbn/pub?gid=497214901&single=true&output=csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Create a vectorstore database and use Cosine Similarity for semantic search within the DB\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"video_collection\",\n",
    "    embedding_function=openai_ef,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "watched_videos = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding new rows to the collection\n",
    "\n",
    "# Convert the 'tags' column to a list of strings (grouped according to its respective row)\n",
    "documents = df[\"tags\"].apply(lambda x: x.split(\",\")).tolist()\n",
    "documents_str = [\", \".join(doc) for doc in documents]\n",
    "\n",
    "# Add the documents to the collection\n",
    "# todo: handle UUIDs\n",
    "ids = [str(i + 1) for i in range(len(documents_str))]\n",
    "\n",
    "# Add new rows to the collection\n",
    "collection.upsert(documents=documents_str, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the collection for the top 3 most similar videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
