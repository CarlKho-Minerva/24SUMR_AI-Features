{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# User Interest Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import random\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Constants\n",
    "\n",
    "new_video_weight = 10\n",
    "starting_weight = 10\n",
    "\n",
    "user_min_interest = 4\n",
    "user_max_interest = 8\n",
    "\n",
    "count_queued_videos = 5\n",
    "\n",
    "# Number of vids to queue before running query again (to save costs)\n",
    "# AKA n_results = 3.\n",
    "\n",
    "# User Actions\n",
    "Like = 1\n",
    "Share = 2\n",
    "Watch = 1  # more than 50% of total duration\n",
    "Loop = 1\n",
    "\n",
    "# Dictionaries - remove\n",
    "watched_videos = {}\n",
    "\n",
    "# AI-Related Constants\n",
    "OPENAI_API_KEY = \"sk-\"\n",
    "OPENAI_EmbeddingModel = \"text-embedding-3-small\"\n",
    "chroma_client = chromadb.PersistentClient(path=\"db\")\n",
    "\n",
    "# Use OpenAI as the embedding model (word to vector)\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=OPENAI_API_KEY,\n",
    "                model_name=OPENAI_EmbeddingModel\n",
    "            )\n",
    "\n",
    "# Create a vectorstore database and use Cosine Similarity for semantic search within the DB\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"Edgur_Video_DB_Vectorstore\",\n",
    "    embedding_function=openai_ef,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},\n",
    ")\n",
    "\n",
    "# DB\n",
    "db_url = \"\" # test spreadsheet\n",
    "df = pd.read_csv(db_url)\n",
    "\n",
    "# Simulation Only (replace user input)\n",
    "chosen_interest_tag = \"Dictionaries\"\n",
    "user1_interests = [\"DevOps\", \"Tests (SAT)\", \"Machine Learning\", \"Cats\", \"Cooking\"] # count: 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_interest_dict(user_interest_list):\n",
    "    if len(user_interest_list) < user_min_interest:\n",
    "        raise ValueError(\"You must have at least 4 interests\")\n",
    "    elif len(user_interest_list) > user_max_interest:\n",
    "        raise ValueError(\"You may have 8 interests at most\")\n",
    "\n",
    "    user_dict_interest = {interest: starting_weight for interest in user_interest_list}\n",
    "    user_dict_interest[\"Random\"] = starting_weight\n",
    "    return user_dict_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe_action_taken(interest_tag, liked=False, shared=False, watched=False, loop_count=0):\n",
    "    \"\"\"\n",
    "    This function calculates the total points based on the user's actions.\n",
    "\n",
    "    Parameters:\n",
    "    interest_tag (str): The tag of the video.\n",
    "    liked (bool): Whether the user liked the video.\n",
    "    shared (bool): Whether the user shared the video.\n",
    "    watched (bool): Whether the user watched the video.\n",
    "    loop_count (int): The number of times the user looped the video.\n",
    "\n",
    "    Returns:\n",
    "    float: The total points calculated based on the user's actions.\n",
    "    \"\"\"\n",
    "    # Actions and their corresponding points to add\n",
    "    Actions = {\n",
    "        \"Like\": Like,\n",
    "        \"Share\": Share,\n",
    "        \"Watch\": Watch,  # more than 50% of total duration\n",
    "        \"Loop\": Loop,\n",
    "    }\n",
    "\n",
    "    total_action_points = 0\n",
    "\n",
    "    if liked:\n",
    "        total_action_points += Actions[\"Like\"]\n",
    "    if shared:\n",
    "        total_action_points += Actions[\"Share\"]\n",
    "    if watched:\n",
    "        total_action_points += Actions[\"Watch\"]\n",
    "    total_action_points += loop_count * Actions[\"Loop\"]\n",
    "\n",
    "    print(f\"\\nUpdating weights for interest tag: {interest_tag}\")\n",
    "    print(f\"Total points to add: {total_action_points}\")\n",
    "\n",
    "    return total_action_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_percentages(user_dict_interest):\n",
    "    \"\"\"\n",
    "    Recalculate the percentage of each interest relative to the total weight.\n",
    "    \"\"\"\n",
    "    total_weight = sum(user_dict_interest.values())\n",
    "    user_dict_percentage = {}\n",
    "    for interest_tag, weight in user_dict_interest.items():\n",
    "        user_dict_percentage[interest_tag] = (weight / total_weight) * 100\n",
    "\n",
    "    return user_dict_percentage\n",
    "\n",
    "def handle_interruptions(user_dict_percentage, interest_tag):\n",
    "    \"\"\"\n",
    "    Handle intentional interruptions and suggest relevant interests (50% dominance) or recommend more of the same interest.\n",
    "\n",
    "    Parameters:\n",
    "    user_dict_percentage (dict): A dictionary where keys are interest tags and values are their percentages.\n",
    "    interest_tag (str): The interest tag to handle.\n",
    "    \"\"\"\n",
    "    interest_percentage = user_dict_percentage.get(interest_tag, 0)\n",
    "\n",
    "    if interest_percentage > 75:\n",
    "        print(f\"Have you been enjoying {interest_tag} so far?\")\n",
    "        response = input()  # Get user's response\n",
    "        if response.lower() == \"yes\":\n",
    "            print(\"Recommend less of the same interest.\")\n",
    "            # Add checkbox code to recommend more videos of the same interest\n",
    "\n",
    "    elif interest_percentage > 50:\n",
    "        print(\"Suggesting relevant interests...\")\n",
    "        # Add slider code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_actions_and_update_weights(\n",
    "    user_dict_interest,\n",
    "    interest_tag,\n",
    "    liked=False,\n",
    "    shared=False,\n",
    "    watched=False,\n",
    "    loop_count=0,\n",
    "):\n",
    "    total_action_points = observe_action_taken(\n",
    "        interest_tag, liked, shared, watched, loop_count\n",
    "    )\n",
    "\n",
    "    # Update raw weights\n",
    "    if interest_tag in user_dict_interest:\n",
    "        user_dict_interest[interest_tag] += total_action_points\n",
    "    else:\n",
    "        user_dict_interest[interest_tag] = starting_weight\n",
    "\n",
    "    # Recalculate percentages\n",
    "    user_dict_percentage = recalculate_percentages(user_dict_interest)\n",
    "\n",
    "    # Handle interruptions\n",
    "    handle_interruptions(user_dict_percentage, interest_tag)\n",
    "\n",
    "    # Sort the interests (\"key=item[1]\") by weight in descending order and keep only the top 10\n",
    "    user_dict_interest = dict(\n",
    "        sorted(user_dict_interest.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    )\n",
    "\n",
    "    return user_dict_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_tag_for_recommendation(user_dict_interest):\n",
    "\n",
    "    total_score = sum(value for value in user_dict_interest.values())\n",
    "    random_value = round(random.uniform(0, total_score), 0)\n",
    "\n",
    "    print(\"_\" * 50)\n",
    "    print(f\"\\nRandom value: {random_value}\\n\")\n",
    "\n",
    "    cumulative_probability = 0\n",
    "    partitions = []\n",
    "\n",
    "    for interest_tag, probability in user_dict_interest.items():\n",
    "        # Save the starting point of the current tag's range (in probability)\n",
    "        previous_cumulative_probability = cumulative_probability\n",
    "\n",
    "        # Add the tag's probability to the cumulative total to get the end point of the tag's range\n",
    "        cumulative_probability += probability\n",
    "\n",
    "        partitions.append(\n",
    "            (interest_tag, previous_cumulative_probability, cumulative_probability)\n",
    "        )\n",
    "\n",
    "        pprint(f\"Checking interest: {interest_tag}, cumulative range: {previous_cumulative_probability} - {cumulative_probability}\")\n",
    "\n",
    "        # If the random value is less than or equal to the cumulative probability up to the current interest,\n",
    "        # select the current interest and stop looking at the rest of the interests.\n",
    "        if random_value <= cumulative_probability:\n",
    "            print(f\"\\nSelected interest: {interest_tag}\\n\")\n",
    "            break\n",
    "\n",
    "    if interest_tag == \"Random\":\n",
    "        interest_tag = random.choice(list(user_dict_interest.keys()))\n",
    "        print(f\"!!Random!! tag selected: {interest_tag}\")\n",
    "        print(\"MODIFY THIS LATER TO POINT TO CSV COLUMN\")\n",
    "        return interest_tag\n",
    "\n",
    "    return interest_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial user-chosen interests\n",
      "\n",
      "(\"{'DevOps': 10, 'Tests (SAT)': 10, 'Machine Learning': 10, 'Cats': 10, \"\n",
      " \"'Dogs': 10, 'Random': 10}\")\n",
      "\n",
      "Updating weights for interest tag: Cats\n",
      "Total points to add: 1\n",
      "(\"Updated interests: {'Cats': 11, 'DevOps': 10, 'Tests (SAT)': 10, 'Machine \"\n",
      " \"Learning': 10, 'Dogs': 10, 'Random': 10}\")\n",
      "__________________________________________________\n",
      "\n",
      "Random value: 3.0\n",
      "\n",
      "'Checking interest: Cats, cumulative range: 0 - 11'\n",
      "\n",
      "Selected interest: Cats\n",
      "\n",
      "Randomly selected tag for recommendation: Cats\n",
      "User Dict Interest: {'Cats': 11, 'DevOps': 10, 'Tests (SAT)': 10, 'Machine Learning': 10, 'Dogs': 10, 'Random': 10}\n",
      "Percentages: {'Cats': 18.0327868852459, 'DevOps': 16.39344262295082, 'Tests (SAT)': 16.39344262295082, 'Machine Learning': 16.39344262295082, 'Dogs': 16.39344262295082, 'Random': 16.39344262295082}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user1_interests = [\"DevOps\", \"Tests (SAT)\", \"Machine Learning\", \"Cats\", \"Dogs\"] # count: 4\n",
    "user_interests = create_user_interest_dict(user1_interests)\n",
    "print(\"Initial user-chosen interests\\n\")\n",
    "pprint(f\"{user_interests}\")\n",
    "\n",
    "user_interests = note_actions_and_update_weights(user_interests, \"Cats\", liked=True)\n",
    "pprint(f\"Updated interests: {user_interests}\")\n",
    "\n",
    "random_tag = get_random_tag_for_recommendation(user_interests)\n",
    "print(f\"Randomly selected tag for recommendation: {random_tag}\")\n",
    "\n",
    "print(f\"User Dict Interest: {user_interests}\\nPercentages: {recalculate_percentages(user_interests)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Ranking Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding new rows to the collection\n",
    "\n",
    "# Convert the 'tags' column to a list of strings (grouped according to its respective row)\n",
    "documents = df[\"tags\"].apply(lambda x: x.split(\",\")).tolist()\n",
    "documents_str = [\", \".join(doc) for doc in documents]\n",
    "\n",
    "# Add the documents to the collection\n",
    "# todo: handle UUIDs\n",
    "ids = [str(i + 1) for i in range(len(documents_str))]\n",
    "\n",
    "# Add new rows to the collection\n",
    "collection.upsert(documents=documents_str, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': None,\n",
      " 'distances': [[0.7705950198622088, 0.7948330884752528, 0.8110350370407104]],\n",
      " 'documents': [['Cryptocurrencies,  Bitcoin,  How it works,  Blockchain '\n",
      "                'technology,  Digital currency',\n",
      "                'Stock markets,  Buying,  Selling,  Basics,  Understanding',\n",
      "                'Deep Learning,  TensorFlow,  Neural Networks,  Artificial '\n",
      "                'Intelligence']],\n",
      " 'embeddings': None,\n",
      " 'ids': [['628', '625', '105']],\n",
      " 'metadatas': [[None, None, None]],\n",
      " 'uris': None}\n",
      "\n",
      "Title: Cryptocurrencies: How Bitcoin Works\n"
     ]
    }
   ],
   "source": [
    "# Query the collection for the top 3 most similar videos\n",
    "\n",
    "results = collection.query(query_texts=[\"Shiba\"], n_results=3)\n",
    "\n",
    "# Print the results\n",
    "pprint(results)\n",
    "\n",
    "# Get the ID of the first result\n",
    "result_id = int(results[\"ids\"][0][0])\n",
    "\n",
    "# Get the title corresponding to the ID\n",
    "title = df.loc[df[\"video_id\"] == result_id, \"video_title\"].values[0]\n",
    "\n",
    "print(f\"\\nTitle: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Cryptocurrencies: How Bitcoin Works\" with ID 628 has been added to watched videos.\n",
      "{628: 'Cryptocurrencies: How Bitcoin Works'}\n",
      "\"Cryptocurrencies: How Bitcoin Works\" with ID 628 will be shown to user again in the future.\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "watched = {} # Should be in a class\n",
    "\n",
    "# Functions handling the watched videos dictionary\n",
    "\n",
    "def add_to_watched(video_id, title, watched_dict):\n",
    "    watched_dict[video_id] = title\n",
    "    print(f'\"{title}\" with ID {video_id} has been added to watched videos.')\n",
    "    return watched_dict\n",
    "\n",
    "def show_to_user_again(video_id, title, watched_dict):\n",
    "    watched_dict.pop(video_id)\n",
    "    print(f'\"{title}\" with ID {video_id} will be shown to user again in the future.')\n",
    "    return watched_dict\n",
    "\n",
    "add_to_watched(result_id, title, watched)\n",
    "print(watched)\n",
    "show_to_user_again(result_id, title, watched)\n",
    "print(watched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the queue\n",
    "queue = {} # should be in class\n",
    "\n",
    "# Function to add videos to the queue\n",
    "def add_to_queue(interest_tag, n_results=5):\n",
    "    # Use ChromaDB to query top 5 videos closest to given interest\n",
    "    results = collection.query(query_texts=[interest_tag], n_results=n_results)\n",
    "    print(f'Queried top {n_results} videos for tag \"{interest_tag}\"')  # Debugging line\n",
    "\n",
    "    # Add the videos to the queue\n",
    "    for i in range(n_results):\n",
    "        result_id = int(results[\"ids\"][0][i])\n",
    "        title = df.loc[df[\"video_id\"] == result_id, \"video_title\"].values[0]\n",
    "        tag = df.loc[df[\"video_id\"] == result_id, \"tags\"].values[0].split(',')[0]  # get the first tag\n",
    "\n",
    "        # Check if the video has already been watched by user\n",
    "        if result_id not in watched:\n",
    "            queue[result_id] = tag\n",
    "            print(f'Added video with ID {result_id} and tag \"{tag}\" to the queue')  # Debugging line\n",
    "\n",
    "\n",
    "    return queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = {} # should be in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queried top 5 videos for tag \"Date\"\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madd_to_queue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 12\u001b[0m, in \u001b[0;36madd_to_queue\u001b[0;34m(interest_tag, n_results)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Add the videos to the queue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_results):\n\u001b[0;32m---> 12\u001b[0m     result_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m     title \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m result_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_title\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     14\u001b[0m     tag \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m result_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# get the first tag\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "add_to_queue(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m queue\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Add the first 5 videos to the queue\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mview_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_interests\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwatched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     28\u001b[0m pprint(user_interests)\n",
      "Cell \u001b[0;32mIn[65], line 7\u001b[0m, in \u001b[0;36mview_video\u001b[0;34m(queue, user_dict_interest, watched_dict)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mview_video\u001b[39m(queue, user_dict_interest, watched_dict):\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Pop the first video from the queue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     video_id, interest_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m queue[video_id]\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Add the video to the watched videos\u001b[39;00m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Recommend and Queue videos function (MAIN)\n",
    "\n",
    "# Function to view a video\n",
    "def view_video(queue, user_dict_interest, watched_dict):\n",
    "\n",
    "    # Pop the first video from the queue\n",
    "    video_id, interest_tag = next(iter(queue.items()))\n",
    "    del queue[video_id]\n",
    "\n",
    "    # Add the video to the watched videos\n",
    "    add_to_watched(video_id, title, watched_dict)\n",
    "\n",
    "    # Update the user's interest weights based on the watched video\n",
    "    note_actions_and_update_weights(user_dict_interest, interest_tag) # SIMULATION - User took no action\n",
    "\n",
    "    # If the queue length drops to 2, get random tag and add more videos to the queue\n",
    "    if len(queue) <= 2:\n",
    "        print(\"\\nAdding more videos to the queue...\\n\")\n",
    "        new_interest_tag = get_random_tag_for_recommendation(user_dict_interest)\n",
    "        add_to_queue(new_interest_tag, count_queued_videos)\n",
    "\n",
    "    return queue\n",
    "\n",
    "# Add the first 5 videos to the queue\n",
    "view_video(queue, user_interests, watched)\n",
    "\n",
    "print()\n",
    "pprint(user_interests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #BreakItDown - Tasks\n",
    "\n",
    "### 1. Mark video as watched ✅\n",
    "- If ID exist\n",
    "- query result skip over id and check again if ID exists\n",
    "- repeat until not \n",
    "\n",
    "### 2. Revised percentage calculation (relative instead of 100%) ✅\n",
    "Will cause a tag to be dominant tho (weight 1000 while others still 10). Mitigated with intentional interruptions (#4). \n",
    "\n",
    "### 3. User class schema ✅\n",
    "- self\n",
    "- interest_weights (dict)\n",
    "- watched_videos (dict)\n",
    "\n",
    "### 4. Intentional Interruptions ✅\n",
    "Handle dominations\n",
    "- 50% -> Suggest relevant interests \n",
    "- 75% -> \"Have you been enjoying {tag name} so far? \"yes\". \"recommend more\". \n",
    "\n",
    "### 5. Modify whisper prompt to return most relevant tag first then extract that for on_user_swipe()\n",
    "in [github](https://github.com/edgurinc/edgur/blob/main/backend/accounts/videoprocessors.py)\n",
    "- To help us later in handling which tag to add weights to given videos have multiple tags. \n",
    "\n",
    "### 6. Decay other interests whenever watching a video ✅\n",
    "except current video tag \n",
    "\n",
    "### 7. Handle irrelevant tags\n",
    "Acknowledge that it will be filled soon, such as \"food\" category\n",
    "\n",
    "### 8. \"Cache\" next 5 videos ✅\n",
    "Run uniformDist+reco only on 3rd video \n",
    "\n",
    "### 9. Min selection Max selection for categories ✅\n",
    "Like tiktok's\n",
    "\n",
    "### 10. Show this to me again (#SpacedRepetition) ✅\n",
    "Remove from watched dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update relative calculation (100)\n",
    "\n",
    "# User schema\n",
    "    # Dict of Interests\n",
    "    # Dict `watched`\n",
    "    # Dict `queue`\n",
    "\n",
    "# Research Relational database\n",
    "    # Tables how do we store?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
